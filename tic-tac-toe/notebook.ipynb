{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tic Tac Toe DRL",
      "provenance": [],
      "authorship_tag": "ABX9TyN8bfDyHTsIAXDXxE6EkPM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomomon/drl-js/blob/main/tic-tac-toe/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBl0Klfol8d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTQEPi62q5i"
      },
      "source": [
        "# Game (Environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTm9-s892yVX"
      },
      "source": [
        "# 0 1 2\n",
        "# 3 4 5\n",
        "# 6 7 8\n",
        "\n",
        "def gameStatus(board):\n",
        "    lines = [\n",
        "        [0, 1, 2],\n",
        "        [3, 4, 5],\n",
        "        [6, 7, 8],\n",
        "        [0, 3, 6],\n",
        "        [1, 4, 7],\n",
        "        [2, 5, 8],\n",
        "        [0, 4, 8],\n",
        "        [2, 4, 6],\n",
        "    ]\n",
        "\n",
        "    # there is a winner\n",
        "    for line in lines:\n",
        "        if (board[line[1]] == board[line[0]] and \n",
        "            board[line[1]] == board[line[2]] and \n",
        "            board[line[1]] != 0):\n",
        "            return board[line[1]]\n",
        "\n",
        "    # tie\n",
        "    if(np.all(np.array(board) != 0)):\n",
        "        return 0.5\n",
        "\n",
        "    # game is not finished\n",
        "    return 0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXrTo_vwVY2y"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paoZzPA1Vckz"
      },
      "source": [
        "### Agent ###\n",
        "\n",
        "def createPolicy():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer((9,)),\n",
        "        layers.Reshape((3, 3, 1,)),\n",
        "        layers.Conv2D(8, (3, 3)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(20, activation = \"relu\"),\n",
        "        layers.Dense(20, activation = \"relu\"),\n",
        "        layers.Dense(9, activation = None)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4dIASq1cVsb"
      },
      "source": [
        "def chooseAction(policy, board, epsilon = 0):\n",
        "    while True:\n",
        "        logits = policy.predict([board])\n",
        "        norm_logits, _ = tf.linalg.normalize(logits)\n",
        "\n",
        "        possible = (board == 0) + 0\n",
        "        possibleLogits = tf.math.multiply(\n",
        "            norm_logits * (1 - epsilon) + epsilon, \n",
        "            possible\n",
        "        )\n",
        "\n",
        "        action = tf.random.categorical(possibleLogits, num_samples = 1)\n",
        "        action = action.numpy().flatten()[0]\n",
        "\n",
        "        # free cell\n",
        "        if(board[action] == 0):\n",
        "            break\n",
        "\n",
        "    return action"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvb1yK-Ylt8"
      },
      "source": [
        "### Agent Memory ###\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self): \n",
        "        self.clear()\n",
        "\n",
        "    def clear(self): \n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def add_to_memory(self, new_observation, new_action, new_reward): \n",
        "        self.observations.append(new_observation)\n",
        "        self.actions.append(new_action)\n",
        "        self.rewards.append(new_reward)\n",
        "\n",
        "    # Helper function to combine a list of Memory objects into a single Memory.\n",
        "    # This will be very useful for batching.\n",
        "    def aggregate_memories(memories):\n",
        "        batch_memory = Memory()\n",
        "\n",
        "        for memory in memories:\n",
        "            for step in zip(memory.observations, memory.actions, memory.rewards):\n",
        "                batch_memory.add_to_memory(*step)\n",
        "\n",
        "        return batch_memory\n",
        "\n",
        "memory = Memory()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6al8fgdZZ7L"
      },
      "source": [
        "def normalize(x):\n",
        "    x -= np.mean(x)\n",
        "    x /= np.std(x)\n",
        "    return x.astype(np.float32)\n",
        "\n",
        "# Compute normalized, discounted, cumulative rewards (i.e., return)\n",
        "# Arguments:\n",
        "#   rewards: reward at timesteps in episode\n",
        "#   gamma: discounting factor\n",
        "# Returns:\n",
        "#   normalized discounted reward\n",
        "def discount_rewards(rewards, gamma = 0.95): \n",
        "    discounted_rewards = np.zeros_like(rewards)\n",
        "    \n",
        "    R = 0\n",
        "    for t in reversed(range(0, len(rewards))):\n",
        "        R = R * gamma + rewards[t]\n",
        "        discounted_rewards[t] = R\n",
        "        \n",
        "    return normalize(discounted_rewards)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1CT1UZeXfuz"
      },
      "source": [
        "def compute_loss(logits, actions, rewards):\n",
        "    neg_logprob = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits, \n",
        "        labels=actions\n",
        "    )\n",
        "    loss = tf.reduce_mean(\n",
        "        neg_logprob * rewards\n",
        "    )\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdMcQ-ImYEk"
      },
      "source": [
        "### Training step (forward and backpropagation) ###\n",
        "\n",
        "def train_step(model, optimizer, observations, actions, discounted_rewards):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(observations)\n",
        "      loss = compute_loss(logits, actions, discounted_rewards)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2FOqw41nNuy"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWvrsjmYnO-l"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrpwyKjcnSeP"
      },
      "source": [
        "def plot(points):\n",
        "    clear_output()\n",
        "    plt.clf()\n",
        "    plt.plot(points)\n",
        "    plt.show()\n",
        "\n",
        "def smooth(points, alpha = 0.6):\n",
        "    smoothed = [points[0]]\n",
        "\n",
        "    for i in range(1, len(points)):\n",
        "        smoothed.append(points[i] * alpha + smoothed[i - 1] * (1 - alpha))\n",
        "\n",
        "    return smoothed"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWxUpuDsbAuK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc92tQCwsH2u"
      },
      "source": [
        "points = []\n",
        "episode = 0\n",
        "policy = createPolicy()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82CNMdBia2js",
        "outputId": "5cab895f-61e7-4480-94e3-28c7e4743e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "learning_rate = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "for episode in range(episode, 500):\n",
        "    board = [0] * 9\n",
        "    memory.clear()\n",
        "    counter = 0\n",
        "    first_time = 1\n",
        "    step = 0\n",
        "    win = 0\n",
        "\n",
        "    eps = 0.99 ** (episode / 2)\n",
        "\n",
        "    player_goes_first = bool(random.getrandbits(1))\n",
        "\n",
        "    while True:\n",
        "        if(player_goes_first and gameStatus(board) == 0):\n",
        "            action = chooseAction(policy, board, eps)\n",
        "\n",
        "            next_board = board\n",
        "            next_board[action] = 1\n",
        "\n",
        "            status = gameStatus(next_board)\n",
        "\n",
        "            if(status == 0): # game goes on\n",
        "                opponent_action = chooseAction(policy, (np.array(next_board) * -1).tolist(), eps)\n",
        "                next_board[opponent_action] = -1\n",
        "\n",
        "                status = gameStatus(next_board)\n",
        "        \n",
        "            reward = status - 0.01 * step\n",
        "            memory.add_to_memory(board, action, reward)\n",
        "\n",
        "            if(status != 0):\n",
        "                win += (status == 1)\n",
        "                counter += 1\n",
        "                next_board = [0] * 9\n",
        "                first_time = 1\n",
        "                step = 0\n",
        "                player_goes_first = bool(random.getrandbits(1))\n",
        "            \n",
        "            if(status != 0 and counter >= 20):\n",
        "                total_reward = sum(memory.rewards)\n",
        "                points.append(win / counter)\n",
        "                plot(smooth(points))\n",
        "                print(f\"{episode} reward: {total_reward}\")\n",
        "                print(f\"{episode} winRat: {win / counter}\")\n",
        "\n",
        "                train_step(\n",
        "                    policy, \n",
        "                    optimizer, \n",
        "                    observations = np.vstack(memory.observations),\n",
        "                    actions = np.array(memory.actions),\n",
        "                    discounted_rewards = discount_rewards(memory.rewards)\n",
        "                )\n",
        "\n",
        "                memory.clear()\n",
        "                board = [0] * 9\n",
        "                counter = 0\n",
        "                first_time = 1\n",
        "                step = 0\n",
        "\n",
        "                break\n",
        "        \n",
        "            board = next_board\n",
        "\n",
        "        elif((not player_goes_first) and gameStatus(board) == 0):\n",
        "            if(first_time):\n",
        "                first_time -= 1\n",
        "                opponent_action = chooseAction(policy, (np.array(board) * -1).tolist())\n",
        "                board[opponent_action] = -1\n",
        "\n",
        "            action = chooseAction(policy, board)\n",
        "\n",
        "            next_board = board\n",
        "            next_board[action] = 1\n",
        "\n",
        "            status = gameStatus(next_board)\n",
        "\n",
        "            if(status == 0): # game goes on\n",
        "                opponent_action = chooseAction(policy, (np.array(next_board) * -1).tolist())\n",
        "                next_board[opponent_action] = -1\n",
        "\n",
        "                status = gameStatus(next_board)\n",
        "        \n",
        "            reward = status - 0.01 * step\n",
        "            memory.add_to_memory(board, action, reward)\n",
        "\n",
        "            if(status != 0):\n",
        "                win += (status == 1)\n",
        "                counter += 1\n",
        "                next_board = [0] * 9\n",
        "                first_time = 1\n",
        "                step = 0\n",
        "                player_goes_first = bool(random.getrandbits(1))\n",
        "            \n",
        "            if(status != 0 and counter >= 20):\n",
        "                total_reward = sum(memory.rewards)\n",
        "                points.append(win / counter)\n",
        "                plot(smooth(points))\n",
        "                print(f\"{episode} reward: {total_reward}\")\n",
        "                print(f\"{episode} winRat: {win / counter}\")\n",
        "\n",
        "                train_step(\n",
        "                    policy, \n",
        "                    optimizer, \n",
        "                    observations = np.vstack(memory.observations),\n",
        "                    actions = np.array(memory.actions),\n",
        "                    discounted_rewards = discount_rewards(memory.rewards)\n",
        "                )\n",
        "\n",
        "                memory.clear()\n",
        "                board = [0] * 9\n",
        "                counter = 0\n",
        "                first_time = 1\n",
        "                step = 0\n",
        "\n",
        "                break\n",
        "        \n",
        "            board = next_board\n",
        "        \n",
        "        else:\n",
        "            print(player_goes_first, gameStatus(board))\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 reward: -0.5\n",
            "5 winRat: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioprskJo78Ba"
      },
      "source": [
        "# Web demo\n",
        "\n",
        "Play against the AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGyNjHFhlJY"
      },
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "def symbol(x):\n",
        "    if x == 1:\n",
        "        return \"X\"\n",
        "    elif x == -1:\n",
        "        return \"O\"\n",
        "    else:\n",
        "        return \"?\"\n",
        "\n",
        "def printBoard(board):\n",
        "    clear_output()\n",
        "    cBoard = list(map(symbol, board))\n",
        "    for i in range(0, 3):\n",
        "        row = \"\"\n",
        "        for j in range(0, 3):\n",
        "            row += (cBoard[j + i * 3]) if (cBoard[j + i * 3] != \"?\") else str(j + i * 3 + 1)\n",
        "            if j != 2:\n",
        "                row += \" | \"\n",
        "        print(row)\n",
        "        if i != 2:\n",
        "            print(\"---------\")\n",
        "\n",
        "def play(policy):\n",
        "    player = (int(input(\"which player you want to be? (1 or 2) \")) + 1) % 2 \n",
        "\n",
        "    board = [0, 0, 0,\n",
        "             0, 0, 0,\n",
        "             0, 0, 0]\n",
        "\n",
        "    winner = 0\n",
        "\n",
        "    for i in range(9):\n",
        "        if (i % 2 == player):\n",
        "            printBoard(board)\n",
        "            action = int(input(\"what cell? \")) - 1\n",
        "        else:\n",
        "            action = chooseAction(policy, board.copy())\n",
        "\n",
        "        board[action] = 1\n",
        "\n",
        "        if(gameStatus(board) != 0):\n",
        "            winner = gameStatus(board)+1\n",
        "            break\n",
        "\n",
        "        board = (np.array(board) * -1).tolist()\n",
        "    \n",
        "    printBoard(board)\n",
        "    if(gameStatus(board) != 0):\n",
        "        print(\"\\nwinner is the\", \"humen\" if winner else \"ai\")\n",
        "    else:\n",
        "        print(\"\\nit's a tie!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuGYnTxMkMOd",
        "outputId": "6a84203f-e49e-4233-ac49-c229bf30bc50"
      },
      "source": [
        "play(policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 | X | O\n",
            "---------\n",
            "O | X | 6\n",
            "---------\n",
            "7 | X | O\n",
            "\n",
            "winner is the humen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RyU3L043ogp"
      },
      "source": [
        "# Deploy to TF.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6h2d--F5EKx"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install tensorflowjs[wizard]\n",
        "!pip install -U ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBh6IN3m4O3l",
        "outputId": "b3b4b9ed-a6c9-4513-f28e-408aa938e1d3"
      },
      "source": [
        "policy.save(\"./model/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8mh__hd4wl_",
        "outputId": "e675aa56-6572-4861-810a-2fece7d9fc64"
      },
      "source": [
        "!tensorflowjs_converter --input_format=keras_saved_model /content/model /content/tfjs_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-16 12:59:12.108668: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    }
  ]
}