{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tic Tac Toe DRL",
      "provenance": [],
      "authorship_tag": "ABX9TyPlC6nBM/d8AJT07DFK5lEU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomomon/drl-js/blob/main/tic-tac-toe/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBl0Klfol8d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTQEPi62q5i"
      },
      "source": [
        "# Game (Environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTm9-s892yVX"
      },
      "source": [
        "# 0 1 2\n",
        "# 3 4 5\n",
        "# 6 7 8\n",
        "\n",
        "def gameStatus(board):\n",
        "    lines = [\n",
        "        [0, 1, 2],\n",
        "        [3, 4, 5],\n",
        "        [6, 7, 8],\n",
        "        [0, 3, 6],\n",
        "        [1, 4, 7],\n",
        "        [2, 5, 8],\n",
        "        [0, 4, 8],\n",
        "        [2, 4, 6],\n",
        "    ]\n",
        "\n",
        "    # there is a winner\n",
        "    for line in lines:\n",
        "        if (board[line[1]] == board[line[0]] and \n",
        "            board[line[1]] == board[line[2]] and \n",
        "            board[line[1]] != 0):\n",
        "            return board[line[1]]\n",
        "\n",
        "    # tie\n",
        "    if(np.all(np.array(board) != 0)):\n",
        "        return 0.5\n",
        "\n",
        "    # game is not finished\n",
        "    return 0"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXrTo_vwVY2y"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paoZzPA1Vckz"
      },
      "source": [
        "### Agent ###\n",
        "\n",
        "def createPolicy():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.InputLayer((9,)),\n",
        "        layers.Dense(20, activation = \"relu\"),\n",
        "        layers.Dropout(0.01),\n",
        "        layers.Dense(20, activation = \"relu\"),\n",
        "        layers.Dropout(0.01),\n",
        "        layers.Dense(9, activation = None)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4dIASq1cVsb"
      },
      "source": [
        "def chooseAction(policy, board):\n",
        "    while True:\n",
        "        logits = policy.predict([board])\n",
        "\n",
        "        possible = (board == 0) + 0\n",
        "        possibleLogits = tf.math.multiply(logits, possible)\n",
        "\n",
        "        action = tf.random.categorical(possibleLogits, num_samples = 1)\n",
        "        action = action.numpy().flatten()[0]\n",
        "\n",
        "        # free cell\n",
        "        if(board[action] == 0):\n",
        "            break\n",
        "\n",
        "    return action"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUvb1yK-Ylt8"
      },
      "source": [
        "### Agent Memory ###\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self): \n",
        "        self.clear()\n",
        "\n",
        "    def clear(self): \n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def add_to_memory(self, new_observation, new_action, new_reward): \n",
        "        self.observations.append(new_observation)\n",
        "        self.actions.append(new_action)\n",
        "        self.rewards.append(new_reward)\n",
        "\n",
        "    # Helper function to combine a list of Memory objects into a single Memory.\n",
        "    # This will be very useful for batching.\n",
        "    def aggregate_memories(memories):\n",
        "        batch_memory = Memory()\n",
        "\n",
        "        for memory in memories:\n",
        "            for step in zip(memory.observations, memory.actions, memory.rewards):\n",
        "                batch_memory.add_to_memory(*step)\n",
        "\n",
        "        return batch_memory\n",
        "\n",
        "memory = Memory()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6al8fgdZZ7L"
      },
      "source": [
        "def normalize(x):\n",
        "    x -= np.mean(x)\n",
        "    x /= np.std(x)\n",
        "    return x.astype(np.float32)\n",
        "\n",
        "# Compute normalized, discounted, cumulative rewards (i.e., return)\n",
        "# Arguments:\n",
        "#   rewards: reward at timesteps in episode\n",
        "#   gamma: discounting factor\n",
        "# Returns:\n",
        "#   normalized discounted reward\n",
        "def discount_rewards(rewards, gamma = 0.95): \n",
        "    discounted_rewards = np.zeros_like(rewards)\n",
        "    \n",
        "    R = 0\n",
        "    for t in reversed(range(0, len(rewards))):\n",
        "        R = R * gamma + rewards[t]\n",
        "        discounted_rewards[t] = R\n",
        "        \n",
        "    return normalize(discounted_rewards)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1CT1UZeXfuz"
      },
      "source": [
        "def compute_loss(logits, actions, rewards):\n",
        "    neg_logprob = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits, \n",
        "        labels=actions\n",
        "    )\n",
        "    loss = tf.reduce_mean(\n",
        "        neg_logprob * rewards\n",
        "    )\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdMcQ-ImYEk"
      },
      "source": [
        "### Training step (forward and backpropagation) ###\n",
        "\n",
        "def train_step(model, optimizer, observations, actions, discounted_rewards):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits = model(observations)\n",
        "      loss = compute_loss(logits, actions, discounted_rewards)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2FOqw41nNuy"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWvrsjmYnO-l"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrpwyKjcnSeP"
      },
      "source": [
        "def plot(points):\n",
        "    clear_output()\n",
        "    plt.clf()\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWxUpuDsbAuK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "82CNMdBia2js",
        "outputId": "88a53bd8-aef5-47aa-9cbe-9cf32906eb75"
      },
      "source": [
        "# points = []\n",
        "learning_rate = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# policy = createPolicy()\n",
        "\n",
        "for episode in range(500):\n",
        "    board = [0] * 9\n",
        "    memory.clear()\n",
        "    counter = 0\n",
        "    first_time = 1\n",
        "\n",
        "    player_goes_first = bool(random.getrandbits(1))\n",
        "\n",
        "    while True:\n",
        "        if(player_goes_first and gameStatus(board) == 0):\n",
        "            action = chooseAction(policy, board)\n",
        "\n",
        "            next_board = board\n",
        "            next_board[action] = 1\n",
        "\n",
        "            status = gameStatus(next_board)\n",
        "\n",
        "            if(status == 0): # game goes on\n",
        "                opponent_action = chooseAction(policy, (np.array(next_board) * -1).tolist())\n",
        "                next_board[opponent_action] = -1\n",
        "\n",
        "                status = gameStatus(next_board)\n",
        "        \n",
        "            reward = status - 0.1\n",
        "            memory.add_to_memory(board, action, reward)\n",
        "\n",
        "            if(status != 0):\n",
        "                counter += 1\n",
        "                next_board = [0] * 9\n",
        "                first_time = 1\n",
        "                player_goes_first = bool(random.getrandbits(1))\n",
        "            \n",
        "            if(status != 0 and counter >= 10):\n",
        "                total_reward = sum(memory.rewards)\n",
        "                print(f\"{episode} reward: {total_reward}\")\n",
        "                points.append(total_reward)\n",
        "                plot(points)\n",
        "\n",
        "                train_step(\n",
        "                    policy, \n",
        "                    optimizer, \n",
        "                    observations = np.vstack(memory.observations),\n",
        "                    actions = np.array(memory.actions),\n",
        "                    discounted_rewards = discount_rewards(memory.rewards)\n",
        "                )\n",
        "\n",
        "                memory.clear()\n",
        "                board = [0] * 9\n",
        "                counter = 0\n",
        "                first_time = 1\n",
        "\n",
        "                break\n",
        "        \n",
        "            board = next_board\n",
        "\n",
        "        elif((not player_goes_first) and gameStatus(board) == 0):\n",
        "            if(first_time):\n",
        "                first_time -= 1\n",
        "                opponent_action = chooseAction(policy, (np.array(board) * -1).tolist())\n",
        "                board[opponent_action] = -1\n",
        "\n",
        "            action = chooseAction(policy, board)\n",
        "\n",
        "            next_board = board\n",
        "            next_board[action] = 1\n",
        "\n",
        "            status = gameStatus(next_board)\n",
        "\n",
        "            if(status == 0): # game goes on\n",
        "                opponent_action = chooseAction(policy, (np.array(next_board) * -1).tolist())\n",
        "                next_board[opponent_action] = -1\n",
        "\n",
        "                status = gameStatus(next_board)\n",
        "        \n",
        "            reward = status - 0.1\n",
        "            memory.add_to_memory(board, action, reward)\n",
        "\n",
        "            if(status != 0):\n",
        "                counter += 1\n",
        "                next_board = [0] * 9\n",
        "                first_time = 1\n",
        "                player_goes_first = bool(random.getrandbits(1))\n",
        "            \n",
        "            if(status != 0 and counter >= 10):\n",
        "                total_reward = sum(memory.rewards)\n",
        "                print(f\"{episode} reward: {total_reward}\")\n",
        "                points.append(total_reward)\n",
        "                plot(points)\n",
        "\n",
        "                train_step(\n",
        "                    policy, \n",
        "                    optimizer, \n",
        "                    observations = np.vstack(memory.observations),\n",
        "                    actions = np.array(memory.actions),\n",
        "                    discounted_rewards = discount_rewards(memory.rewards)\n",
        "                )\n",
        "\n",
        "                memory.clear()\n",
        "                board = [0] * 9\n",
        "                counter = 0\n",
        "                first_time = 1\n",
        "\n",
        "                break\n",
        "        \n",
        "            board = next_board\n",
        "        \n",
        "        else:\n",
        "            print(player_goes_first, gameStatus(board))\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E431HiZ82loH"
      },
      "source": [
        "if(player_goes_first == 0 and gameStatus(next_board, player_goes_first) == 0):\n",
        "            opponent_action = chooseAction(policy, (np.array(board) * -1).tolist())\n",
        "            board[opponent_action] = -1\n",
        "\n",
        "        if(gameStatus(next_board, player_goes_first) == 0):\n",
        "            action = chooseAction(policy, board)\n",
        "\n",
        "            next_board = board\n",
        "            next_board[action] = 1\n",
        "        \n",
        "        if(player_goes_first == 1 and gameStatus(next_board, player_goes_first) == 0):\n",
        "            opponent_action = chooseAction(policy, (np.array(next_board) * -1).tolist())\n",
        "            next_board[opponent_action] = -1\n",
        "            player_goes_first += 2\n",
        "\n",
        "        status = gameStatus(next_board, player_goes_first)\n",
        "\n",
        "        reward = status - 0.1\n",
        "        memory.add_to_memory(board, action, reward)\n",
        "\n",
        "        if(status != 0):\n",
        "            counter += 1\n",
        "            next_board = [0] * 9\n",
        "\n",
        "        if(status != 0 and counter >= 10):\n",
        "\n",
        "            total_reward = sum(memory.rewards)\n",
        "            if(episode % 1 == 0):\n",
        "                print(f\"{episode} reward: {total_reward}\")\n",
        "\n",
        "            train_step(\n",
        "                policy, \n",
        "                optimizer, \n",
        "                observations = np.vstack(memory.observations),\n",
        "                actions = np.array(memory.actions),\n",
        "                discounted_rewards = discount_rewards(memory.rewards)\n",
        "            )\n",
        "\n",
        "            memory.clear()\n",
        "            board = [0] * 9\n",
        "            counter = 0\n",
        "\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioprskJo78Ba"
      },
      "source": [
        "# Web demo\n",
        "\n",
        "Play against the AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGyNjHFhlJY"
      },
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "def symbol(x):\n",
        "    if x == 1:\n",
        "        return \"X\"\n",
        "    elif x == -1:\n",
        "        return \"O\"\n",
        "    else:\n",
        "        return \"?\"\n",
        "\n",
        "def printBoard(board):\n",
        "    clear_output()\n",
        "    cBoard = list(map(symbol, board))\n",
        "    for i in range(0, 3):\n",
        "        row = \"\"\n",
        "        for j in range(0, 3):\n",
        "            row += (cBoard[j + i * 3]) if (cBoard[j + i * 3] != \"?\") else str(j + i * 3 + 1)\n",
        "            if j != 2:\n",
        "                row += \" | \"\n",
        "        print(row)\n",
        "        if i != 2:\n",
        "            print(\"---------\")\n",
        "\n",
        "def play(policy):\n",
        "    player = (int(input(\"which player you want to be? (1 or 2) \")) + 1) % 2 \n",
        "\n",
        "    board = [0, 0, 0,\n",
        "             0, 0, 0,\n",
        "             0, 0, 0]\n",
        "\n",
        "    winner = 0\n",
        "\n",
        "    for i in range(9):\n",
        "        if (i % 2 == player):\n",
        "            printBoard(board)\n",
        "            action = int(input(\"what cell? \")) - 1\n",
        "        else:\n",
        "            action = chooseAction(policy, board.copy())\n",
        "\n",
        "        board[action] = 1\n",
        "\n",
        "        if(gameStatus(board, player) != 0):\n",
        "            winner = gameStatus(board, player)\n",
        "            break\n",
        "\n",
        "        board = (np.array(board) * -1).tolist()\n",
        "    \n",
        "    printBoard(board)\n",
        "    if(gameStatus(board) != 0):\n",
        "        print(\"\\nwinner is the\", \"humen\" if winner else \"ai\")\n",
        "    else:\n",
        "        print(\"\\nit's a tie!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "NuGYnTxMkMOd",
        "outputId": "9c8a39fc-28b0-4c63-e9da-ddfda401e199"
      },
      "source": [
        "play(policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X | 2 | O\n",
            "---------\n",
            "4 | X | O\n",
            "---------\n",
            "7 | O | X\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-a5184b472d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-176-2deaa108a071>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(policy)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprintBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nwinner is the\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"humen\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"ai\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: gameStatus() missing 1 required positional argument: 'playerParity'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RyU3L043ogp"
      },
      "source": [
        "# Deploy to TF.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6h2d--F5EKx"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install tensorflowjs[wizard]\n",
        "!pip install -U ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBh6IN3m4O3l",
        "outputId": "3f01d5a7-e0c0-4ff9-84e0-1283d5a29c9b"
      },
      "source": [
        "policy.save(\"./model/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8mh__hd4wl_",
        "outputId": "d3784188-bcdb-4b29-ed7f-7d591f706b19"
      },
      "source": [
        "!tensorflowjs_converter --input_format=keras_saved_model /content/model /content/tfjs_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-12 22:01:36.565801: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    }
  ]
}