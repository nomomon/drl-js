{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tic Tac Toe RL",
      "provenance": [],
      "authorship_tag": "ABX9TyO6a+xATFfifTfZ/w2+ghmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nomomon/drl-js/blob/main/tic%20tac%20toe/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBl0Klfol8d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIr_4QOSoqz1"
      },
      "source": [
        "class Policy(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Policy, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu, input_shape = (-1, 9))\n",
        "        self.dense2 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "        self.dense3 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(inputs)\n",
        "        return self.dense3(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWSoqHtCgZDF"
      },
      "source": [
        "policy = Policy()\n",
        "policy.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(), \n",
        "    loss = tf.keras.losses.BinaryCrossentropy(), \n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQzy9PFwBynq",
        "outputId": "0c880bb7-5efd-4433-f674-d6f62de3004b"
      },
      "source": [
        "policy.predict([[1, 0, -1, 0, -1, 0, 1, 0, 0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.90546757]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xMcOiKHDgKY",
        "outputId": "f26fdc34-8199-40f6-96be-272f41ed5420"
      },
      "source": [
        "policy.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"policy\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  40        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  40        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  5         \n",
            "=================================================================\n",
            "Total params: 85\n",
            "Trainable params: 85\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtDn5YM2Dq6f"
      },
      "source": [
        "# 0 1 2\n",
        "# 3 4 5\n",
        "# 6 7 8\n",
        "\n",
        "def gameState(board):\n",
        "    lines = [\n",
        "        [0, 1, 2],\n",
        "        [3, 4, 5],\n",
        "        [6, 7, 8],\n",
        "        [0, 3, 6],\n",
        "        [1, 4, 7],\n",
        "        [2, 5, 8],\n",
        "        [0, 4, 8],\n",
        "        [2, 4, 6],\n",
        "    ]\n",
        "    for line in lines:\n",
        "        if (board[line[0]] == board[line[1]] and board[line[1]] == board[line[2]] and board[line[1]] != 0):\n",
        "            return board[line[1]]\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCvadvILJXb",
        "outputId": "e570ed23-8efe-423c-cfad-867a45aadde2"
      },
      "source": [
        "gameState([0, 0, 0, \n",
        "           1, 1, 1, \n",
        "           1, 0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh9XVowvV6zS"
      },
      "source": [
        "def chooseAction(policy, board):\n",
        "    probs = [0, 0, 0,\n",
        "             0, 0, 0, \n",
        "             0, 0, 0]\n",
        "\n",
        "    for i, cell in enumerate(board):\n",
        "        if cell == 0:\n",
        "            playBoard = board\n",
        "            playBoard[i] = 1\n",
        "\n",
        "            probs[i] = policy.predict([playBoard])[0][0]\n",
        "\n",
        "    maxprob = probs[0]\n",
        "    maxi = 0\n",
        "\n",
        "    for i, prob in enumerate(probs):\n",
        "        if prob >= maxprob:\n",
        "            maxprob = prob\n",
        "            maxi = i\n",
        "\n",
        "    return maxi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swim8Yg_XuGH",
        "outputId": "e9f049c6-d067-4091-8bbd-a4ce4630cf8b"
      },
      "source": [
        "chooseAction(policy, [0, 0, 1,\n",
        "                      1, 1, 0,\n",
        "                      0, 0, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCMx0nsMYP0p"
      },
      "source": [
        "def getData(policy):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    board = [0, 0, 0,\n",
        "             0, 0, 0,\n",
        "             0, 0, 0]\n",
        "\n",
        "    winner = 0\n",
        "\n",
        "    for i in range(9):\n",
        "        action = chooseAction(policy, board.copy())\n",
        "        \n",
        "        board[action] = 1\n",
        "\n",
        "\n",
        "        X.append(board)\n",
        "        y.append((i % 2) * 2 - 1)\n",
        "\n",
        "        if(gameState(board) != 0):\n",
        "            winner = (i % 2) * 2 - 1\n",
        "            break\n",
        "\n",
        "        board = (np.array(board) * -1).tolist()\n",
        "\n",
        "    y = list(map(lambda q: ((q == winner) - 0), y))\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwIXutNKZB3y",
        "outputId": "aba5dff1-d4eb-4519-cd40-af879553d5d0"
      },
      "source": [
        "getData(policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "  [1, 0, 0, 0, 0, 0, 0, 0, -1],\n",
              "  [-1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "  [1, 1, 0, 0, 0, 0, 0, -1, -1],\n",
              "  [-1, -1, 1, 0, 0, 0, 0, 1, 1],\n",
              "  [1, 1, -1, 1, 0, 0, 0, -1, -1],\n",
              "  [-1, -1, 1, -1, 0, 1, 0, 1, 1]],\n",
              " [1, 0, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ-6h798fnmE",
        "outputId": "fe33dcaf-053d-44fa-ff4d-707d92e73a5a"
      },
      "source": [
        "for i in range(100):\n",
        "    X, y = getData(policy)\n",
        "    policy.fit(X, y, epochs = 1, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['policy/dense/kernel:0', 'policy/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['policy/dense/kernel:0', 'policy/dense/bias:0'] when minimizing the loss.\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6529 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6500 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6471 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6443 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6415 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6386 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6358 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6330 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6302 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6275 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6245 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6214 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6184 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6153 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6122 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6092 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6061 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6031 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6000 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5970 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5940 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5910 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5881 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5851 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5822 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5793 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5764 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5735 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5707 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5679 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5651 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5623 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5595 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5568 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5541 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5514 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5487 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5460 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5434 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5408 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5382 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5356 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5330 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5305 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5280 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5255 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5230 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5206 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5182 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5157 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5134 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5110 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5086 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5063 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5040 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5017 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4994 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4971 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4949 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4927 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4905 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4883 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4861 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4840 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4818 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4797 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4776 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4755 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4734 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4714 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4693 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4673 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6153 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6140 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6121 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6098 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6071 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6042 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6012 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5980 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5947 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5913 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5878 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5843 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5808 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5773 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5737 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5702 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5667 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5632 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6859 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6824 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6787 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6748 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6709 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6669 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6628 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6588 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6547 - binary_accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6506 - binary_accuracy: 0.5714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGyNjHFhlJY"
      },
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "def symbol(x):\n",
        "    if x == 1:\n",
        "        return \"X\"\n",
        "    elif x == -1:\n",
        "        return \"O\"\n",
        "    else:\n",
        "        return \"?\"\n",
        "\n",
        "def printBoard(board):\n",
        "    clear_output()\n",
        "    cBoard = list(map(symbol, board))\n",
        "    for i in range(0, 3):\n",
        "        row = \"\"\n",
        "        for j in range(0, 3):\n",
        "            row += (cBoard[j + i * 3]) if (cBoard[j + i * 3] != \"?\") else str(j + i * 3 + 1)\n",
        "            if j != 2:\n",
        "                row += \" | \"\n",
        "        print(row)\n",
        "        if i != 2:\n",
        "            print(\"---------\")\n",
        "\n",
        "def play(policy):\n",
        "    player = (int(input(\"which player you want to be? (1 or 2) \")) + 1) % 2 \n",
        "\n",
        "    board = [0, 0, 0,\n",
        "             0, 0, 0,\n",
        "             0, 0, 0]\n",
        "\n",
        "    winner = 0\n",
        "\n",
        "    for i in range(9):\n",
        "        if (i % 2 == player):\n",
        "            printBoard(board)\n",
        "            action = int(input(\"what cell? \")) - 1\n",
        "        else:\n",
        "            action = chooseAction(policy, board.copy())\n",
        "\n",
        "        board[action] = 1\n",
        "\n",
        "        if(gameState(board) != 0):\n",
        "            winner = i % 2 == player\n",
        "            break\n",
        "\n",
        "        board = (np.array(board) * -1).tolist()\n",
        "    \n",
        "    printBoard(board)\n",
        "    if(gameState(board) != 0):\n",
        "        print(\"\\nwinner is the\", \"humen\" if winner else \"ai\")\n",
        "    else:\n",
        "        print(\"\\nit's a tie!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuGYnTxMkMOd",
        "outputId": "ff1dcd2a-390d-4927-8328-1d0d2bb8b3d0"
      },
      "source": [
        "play(policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O | X | 3\n",
            "---------\n",
            "4 | X | O\n",
            "---------\n",
            "X | X | O\n",
            "\n",
            "winner is the humen\n"
          ]
        }
      ]
    }
  ]
}